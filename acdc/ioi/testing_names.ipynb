{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAMES = [\n",
    "    \"Michael\",\n",
    "    \"Christopher\",\n",
    "    \"Jessica\",\n",
    "    \"Matthew\",\n",
    "    \"Ashley\",\n",
    "    \"Jennifer\",\n",
    "    \"Joshua\",\n",
    "    \"Amanda\",\n",
    "    \"Daniel\",\n",
    "    \"David\",\n",
    "    \"James\",\n",
    "    \"Robert\",\n",
    "    \"John\",\n",
    "    \"Joseph\",\n",
    "    \"Andrew\",\n",
    "    \"Ryan\",\n",
    "    \"Brandon\",\n",
    "    \"Jason\",\n",
    "    \"Justin\",\n",
    "    \"Sarah\",\n",
    "    \"William\",\n",
    "    \"Jonathan\",\n",
    "    \"Stephanie\",\n",
    "    \"Brian\",\n",
    "    \"Nicole\",\n",
    "    \"Nicholas\",\n",
    "    \"Anthony\",\n",
    "    \"Heather\",\n",
    "    \"Eric\",\n",
    "    \"Elizabeth\",\n",
    "    \"Adam\",\n",
    "    \"Megan\",\n",
    "    \"Melissa\",\n",
    "    \"Kevin\",\n",
    "    \"Steven\",\n",
    "    \"Thomas\",\n",
    "    \"Timothy\",\n",
    "    \"Christina\",\n",
    "    \"Kyle\",\n",
    "    \"Rachel\",\n",
    "    \"Laura\",\n",
    "    \"Lauren\",\n",
    "    \"Amber\",\n",
    "    \"Brittany\",\n",
    "    \"Danielle\",\n",
    "    \"Richard\",\n",
    "    \"Kimberly\",\n",
    "    \"Jeffrey\",\n",
    "    \"Amy\",\n",
    "    \"Crystal\",\n",
    "    \"Michelle\",\n",
    "    \"Tiffany\",\n",
    "    \"Jeremy\",\n",
    "    \"Benjamin\",\n",
    "    \"Mark\",\n",
    "    \"Emily\",\n",
    "    \"Aaron\",\n",
    "    \"Charles\",\n",
    "    \"Rebecca\",\n",
    "    \"Jacob\",\n",
    "    \"Stephen\",\n",
    "    \"Patrick\",\n",
    "    \"Sean\",\n",
    "    \"Erin\",\n",
    "    \"Jamie\",\n",
    "    \"Kelly\",\n",
    "    \"Samantha\",\n",
    "    \"Nathan\",\n",
    "    \"Sara\",\n",
    "    \"Dustin\",\n",
    "    \"Paul\",\n",
    "    \"Angela\",\n",
    "    \"Tyler\",\n",
    "    \"Scott\",\n",
    "    \"Katherine\",\n",
    "    \"Andrea\",\n",
    "    \"Gregory\",\n",
    "    \"Erica\",\n",
    "    \"Mary\",\n",
    "    \"Travis\",\n",
    "    \"Lisa\",\n",
    "    \"Kenneth\",\n",
    "    \"Bryan\",\n",
    "    \"Lindsey\",\n",
    "    \"Kristen\",\n",
    "    \"Jose\",\n",
    "    \"Alexander\",\n",
    "    \"Jesse\",\n",
    "    \"Katie\",\n",
    "    \"Lindsay\",\n",
    "    \"Shannon\",\n",
    "    \"Vanessa\",\n",
    "    \"Courtney\",\n",
    "    \"Christine\",\n",
    "    \"Alicia\",\n",
    "    \"Cody\",\n",
    "    \"Allison\",\n",
    "    \"Bradley\",\n",
    "    \"Samuel\",\n",
    "]\n",
    "\n",
    "ABC_TEMPLATES = [\n",
    "    \"Then, [A], [B] and [C] went to the [PLACE]. [B] and [C] gave a [OBJECT] to [A]\",\n",
    "    \"Afterwards [A], [B] and [C] went to the [PLACE]. [B] and [C] gave a [OBJECT] to [A]\",\n",
    "    \"When [A], [B] and [C] arrived at the [PLACE], [B] and [C] gave a [OBJECT] to [A]\",\n",
    "    \"Friends [A], [B] and [C] went to the [PLACE]. [B] and [C] gave a [OBJECT] to [A]\",\n",
    "]\n",
    "\n",
    "BAC_TEMPLATES = [\n",
    "    template.replace(\"[B]\", \"[A]\", 1).replace(\"[A]\", \"[B]\", 1)\n",
    "    for template in ABC_TEMPLATES\n",
    "]\n",
    "\n",
    "BABA_TEMPLATES = [\n",
    "    \"Then, [B] and [A] went to the [PLACE]. [B] gave a [OBJECT] to [A]\",\n",
    "    \"Then, [B] and [A] had a lot of fun at the [PLACE]. [B] gave a [OBJECT] to [A]\",\n",
    "    \"Then, [B] and [A] were working at the [PLACE]. [B] decided to give a [OBJECT] to [A]\",\n",
    "    \"Then, [B] and [A] were thinking about going to the [PLACE]. [B] wanted to give a [OBJECT] to [A]\",\n",
    "    \"Then, [B] and [A] had a long argument, and afterwards [B] said to [A]\",\n",
    "    \"After [B] and [A] went to the [PLACE], [B] gave a [OBJECT] to [A]\",\n",
    "    \"When [B] and [A] got a [OBJECT] at the [PLACE], [B] decided to give it to [A]\",\n",
    "    \"When [B] and [A] got a [OBJECT] at the [PLACE], [B] decided to give the [OBJECT] to [A]\",\n",
    "    \"While [B] and [A] were working at the [PLACE], [B] gave a [OBJECT] to [A]\",\n",
    "    \"While [B] and [A] were commuting to the [PLACE], [B] gave a [OBJECT] to [A]\",\n",
    "    \"After the lunch, [B] and [A] went to the [PLACE]. [B] gave a [OBJECT] to [A]\",\n",
    "    \"Afterwards, [B] and [A] went to the [PLACE]. [B] gave a [OBJECT] to [A]\",\n",
    "    \"Then, [B] and [A] had a long argument. Afterwards [B] said to [A]\",\n",
    "    \"The [PLACE] [B] and [A] went to had a [OBJECT]. [B] gave it to [A]\",\n",
    "    \"Friends [B] and [A] found a [OBJECT] at the [PLACE]. [B] gave it to [A]\",\n",
    "]\n",
    "\n",
    "BABA_LONG_TEMPLATES = [\n",
    "    \"Then in the morning, [B] and [A] went to the [PLACE]. [B] gave a [OBJECT] to [A]\",\n",
    "    \"Then in the morning, [B] and [A] had a lot of fun at the [PLACE]. [B] gave a [OBJECT] to [A]\",\n",
    "    \"Then in the morning, [B] and [A] were working at the [PLACE]. [B] decided to give a [OBJECT] to [A]\",\n",
    "    \"Then in the morning, [B] and [A] were thinking about going to the [PLACE]. [B] wanted to give a [OBJECT] to [A]\",\n",
    "    \"Then in the morning, [B] and [A] had a long argument, and afterwards [B] said to [A]\",\n",
    "    \"After taking a long break [B] and [A] went to the [PLACE], [B] gave a [OBJECT] to [A]\",\n",
    "    \"When soon afterwards [B] and [A] got a [OBJECT] at the [PLACE], [B] decided to give it to [A]\",\n",
    "    \"When soon afterwards [B] and [A] got a [OBJECT] at the [PLACE], [B] decided to give the [OBJECT] to [A]\",\n",
    "    \"While spending time together [B] and [A] were working at the [PLACE], [B] gave a [OBJECT] to [A]\",\n",
    "    \"While spending time together [B] and [A] were commuting to the [PLACE], [B] gave a [OBJECT] to [A]\",\n",
    "    \"After the lunch in the afternoon, [B] and [A] went to the [PLACE]. [B] gave a [OBJECT] to [A]\",\n",
    "    \"Afterwards, while spending time together [B] and [A] went to the [PLACE]. [B] gave a [OBJECT] to [A]\",\n",
    "    \"Then in the morning afterwards, [B] and [A] had a long argument. Afterwards [B] said to [A]\",\n",
    "    \"The local big [PLACE] [B] and [A] went to had a [OBJECT]. [B] gave it to [A]\",\n",
    "    \"Friends separated at birth [B] and [A] found a [OBJECT] at the [PLACE]. [B] gave it to [A]\",\n",
    "]\n",
    "\n",
    "BABA_LATE_IOS = [\n",
    "    \"Then, [B] and [A] went to the [PLACE]. [B] gave a [OBJECT] to [A]\",\n",
    "    \"Then, [B] and [A] had a lot of fun at the [PLACE]. [B] gave a [OBJECT] to [A]\",\n",
    "    \"Then, [B] and [A] were working at the [PLACE]. [B] decided to give a [OBJECT] to [A]\",\n",
    "    \"Then, [B] and [A] were thinking about going to the [PLACE]. [B] wanted to give a [OBJECT] to [A]\",\n",
    "    \"Then, [B] and [A] had a long argument and after that [B] said to [A]\",\n",
    "    \"After the lunch, [B] and [A] went to the [PLACE]. [B] gave a [OBJECT] to [A]\",\n",
    "    \"Afterwards, [B] and [A] went to the [PLACE]. [B] gave a [OBJECT] to [A]\",\n",
    "    \"Then, [B] and [A] had a long argument. Afterwards [B] said to [A]\",\n",
    "]\n",
    "\n",
    "BABA_EARLY_IOS = [\n",
    "    \"Then [B] and [A] went to the [PLACE], and [B] gave a [OBJECT] to [A]\",\n",
    "    \"Then [B] and [A] had a lot of fun at the [PLACE], and [B] gave a [OBJECT] to [A]\",\n",
    "    \"Then [B] and [A] were working at the [PLACE], and [B] decided to give a [OBJECT] to [A]\",\n",
    "    \"Then [B] and [A] were thinking about going to the [PLACE], and [B] wanted to give a [OBJECT] to [A]\",\n",
    "    \"Then [B] and [A] had a long argument, and after that [B] said to [A]\",\n",
    "    \"After the lunch [B] and [A] went to the [PLACE], and [B] gave a [OBJECT] to [A]\",\n",
    "    \"Afterwards [B] and [A] went to the [PLACE], and [B] gave a [OBJECT] to [A]\",\n",
    "    \"Then [B] and [A] had a long argument, and afterwards [B] said to [A]\",\n",
    "]\n",
    "\n",
    "TEMPLATES_VARIED_MIDDLE = [\n",
    "    \"\",\n",
    "]\n",
    "\n",
    "# no end of texts, GPT-2 small wasn't trained this way (ask Arthur)\n",
    "# warnings.warn(\"Adding end of text prefixes!\")\n",
    "# for TEMPLATES in [BABA_TEMPLATES, BABA_EARLY_IOS, BABA_LATE_IOS]:\n",
    "#     for i in range(len(TEMPLATES)):\n",
    "#         TEMPLATES[i] = \"<|endoftext|>\" + TEMPLATES[i]\n",
    "\n",
    "ABBA_TEMPLATES = BABA_TEMPLATES[:]\n",
    "ABBA_LATE_IOS = BABA_LATE_IOS[:]\n",
    "ABBA_EARLY_IOS = BABA_EARLY_IOS[:]\n",
    "\n",
    "for TEMPLATES in [ABBA_TEMPLATES, ABBA_LATE_IOS, ABBA_EARLY_IOS]:\n",
    "    for i in range(len(TEMPLATES)):\n",
    "        first_clause = True\n",
    "        for j in range(1, len(TEMPLATES[i]) - 1):\n",
    "            if TEMPLATES[i][j - 1 : j + 2] == \"[B]\" and first_clause:\n",
    "                TEMPLATES[i] = TEMPLATES[i][:j] + \"A\" + TEMPLATES[i][j + 1 :]\n",
    "            elif TEMPLATES[i][j - 1 : j + 2] == \"[A]\" and first_clause:\n",
    "                first_clause = False\n",
    "                TEMPLATES[i] = TEMPLATES[i][:j] + \"B\" + TEMPLATES[i][j + 1 :]\n",
    "\n",
    "VERBS = [\" tried\", \" said\", \" decided\", \" wanted\", \" gave\"]\n",
    "PLACES = [\n",
    "    \"store\",\n",
    "    \"garden\",\n",
    "    \"restaurant\",\n",
    "    \"school\",\n",
    "    \"hospital\",\n",
    "    \"office\",\n",
    "    \"house\",\n",
    "    \"station\",\n",
    "]\n",
    "OBJECTS = [\n",
    "    \"ring\",\n",
    "    \"kiss\",\n",
    "    \"bone\",\n",
    "    \"basketball\",\n",
    "    \"computer\",\n",
    "    \"necklace\",\n",
    "    \"drink\",\n",
    "    \"snack\",\n",
    "]\n",
    "ANIMALS = [\n",
    "    \"dog\",\n",
    "    \"cat\",\n",
    "    \"snake\",\n",
    "    \"elephant\",\n",
    "    \"beetle\",\n",
    "    \"hippo\",\n",
    "    \"giraffe\",\n",
    "    \"tiger\",\n",
    "    \"husky\",\n",
    "    \"lion\",\n",
    "    \"panther\",\n",
    "    \"whale\",\n",
    "    \"dolphin\",\n",
    "    \"beaver\",\n",
    "    \"rabbit\",\n",
    "    \"fox\",\n",
    "    \"lamb\",\n",
    "    \"ferret\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/pythia-70m-deduped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_gpt2 = AutoTokenizer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing templates that are too long for pythia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template: Then, [A], [B] and [C] went to the [PLACE]. [B] and [C] gave a [OBJECT] to [A]\n",
      "Token ID: 5872, Token: Then\n",
      "Token ID: 13, Token: ,\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 34, Token: A\n",
      "Token ID: 1092, Token: ],\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 35, Token: B\n",
      "Token ID: 62, Token: ]\n",
      "Token ID: 285, Token:  and\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 36, Token: C\n",
      "Token ID: 62, Token: ]\n",
      "Token ID: 2427, Token:  went\n",
      "Token ID: 281, Token:  to\n",
      "Token ID: 253, Token:  the\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 3859, Token: PL\n",
      "Token ID: 9566, Token: ACE\n",
      "Token ID: 1570, Token: ].\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 35, Token: B\n",
      "Token ID: 62, Token: ]\n",
      "Token ID: 285, Token:  and\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 36, Token: C\n",
      "Token ID: 62, Token: ]\n",
      "Token ID: 3534, Token:  gave\n",
      "Token ID: 247, Token:  a\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 35581, Token: OBJECT\n",
      "Token ID: 62, Token: ]\n",
      "Token ID: 281, Token:  to\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 34, Token: A\n",
      "Token ID: 62, Token: ]\n",
      "\n",
      "\n",
      "Template: Afterwards [A], [B] and [C] went to the [PLACE]. [B] and [C] gave a [OBJECT] to [A]\n",
      "Token ID: 4553, Token: After\n",
      "Token ID: 4515, Token: wards\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 34, Token: A\n",
      "Token ID: 1092, Token: ],\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 35, Token: B\n",
      "Token ID: 62, Token: ]\n",
      "Token ID: 285, Token:  and\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 36, Token: C\n",
      "Token ID: 62, Token: ]\n",
      "Token ID: 2427, Token:  went\n",
      "Token ID: 281, Token:  to\n",
      "Token ID: 253, Token:  the\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 3859, Token: PL\n",
      "Token ID: 9566, Token: ACE\n",
      "Token ID: 1570, Token: ].\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 35, Token: B\n",
      "Token ID: 62, Token: ]\n",
      "Token ID: 285, Token:  and\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 36, Token: C\n",
      "Token ID: 62, Token: ]\n",
      "Token ID: 3534, Token:  gave\n",
      "Token ID: 247, Token:  a\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 35581, Token: OBJECT\n",
      "Token ID: 62, Token: ]\n",
      "Token ID: 281, Token:  to\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 34, Token: A\n",
      "Token ID: 62, Token: ]\n",
      "\n",
      "\n",
      "Template: When [A], [B] and [C] arrived at the [PLACE], [B] and [C] gave a [OBJECT] to [A]\n",
      "Token ID: 3039, Token: When\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 34, Token: A\n",
      "Token ID: 1092, Token: ],\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 35, Token: B\n",
      "Token ID: 62, Token: ]\n",
      "Token ID: 285, Token:  and\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 36, Token: C\n",
      "Token ID: 62, Token: ]\n",
      "Token ID: 7244, Token:  arrived\n",
      "Token ID: 387, Token:  at\n",
      "Token ID: 253, Token:  the\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 3859, Token: PL\n",
      "Token ID: 9566, Token: ACE\n",
      "Token ID: 1092, Token: ],\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 35, Token: B\n",
      "Token ID: 62, Token: ]\n",
      "Token ID: 285, Token:  and\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 36, Token: C\n",
      "Token ID: 62, Token: ]\n",
      "Token ID: 3534, Token:  gave\n",
      "Token ID: 247, Token:  a\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 35581, Token: OBJECT\n",
      "Token ID: 62, Token: ]\n",
      "Token ID: 281, Token:  to\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 34, Token: A\n",
      "Token ID: 62, Token: ]\n",
      "\n",
      "\n",
      "Template: Friends [A], [B] and [C] went to the [PLACE]. [B] and [C] gave a [OBJECT] to [A]\n",
      "Token ID: 39, Token: F\n",
      "Token ID: 15145, Token: riends\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 34, Token: A\n",
      "Token ID: 1092, Token: ],\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 35, Token: B\n",
      "Token ID: 62, Token: ]\n",
      "Token ID: 285, Token:  and\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 36, Token: C\n",
      "Token ID: 62, Token: ]\n",
      "Token ID: 2427, Token:  went\n",
      "Token ID: 281, Token:  to\n",
      "Token ID: 253, Token:  the\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 3859, Token: PL\n",
      "Token ID: 9566, Token: ACE\n",
      "Token ID: 1570, Token: ].\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 35, Token: B\n",
      "Token ID: 62, Token: ]\n",
      "Token ID: 285, Token:  and\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 36, Token: C\n",
      "Token ID: 62, Token: ]\n",
      "Token ID: 3534, Token:  gave\n",
      "Token ID: 247, Token:  a\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 35581, Token: OBJECT\n",
      "Token ID: 62, Token: ]\n",
      "Token ID: 281, Token:  to\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 34, Token: A\n",
      "Token ID: 62, Token: ]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for temp in ABC_TEMPLATES:\n",
    "    tokenized = tokenizer.encode(temp)\n",
    "    print(f\"Template: {temp}\")\n",
    "    for token in tokenized:\n",
    "        print(f\"Token ID: {token}, Token: {tokenizer.decode([token])}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template: Then, [A], [B] and [C] went to the [PLACE]. [B] and [C] gave a [OBJECT] to [A]\n",
      "Token ID: 6423, Token: Then\n",
      "Token ID: 11, Token: ,\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 32, Token: A\n",
      "Token ID: 4357, Token: ],\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 33, Token: B\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 290, Token:  and\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 34, Token: C\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 1816, Token:  went\n",
      "Token ID: 284, Token:  to\n",
      "Token ID: 262, Token:  the\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 6489, Token: PL\n",
      "Token ID: 11598, Token: ACE\n",
      "Token ID: 4083, Token: ].\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 33, Token: B\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 290, Token:  and\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 34, Token: C\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 2921, Token:  gave\n",
      "Token ID: 257, Token:  a\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 9864, Token: OB\n",
      "Token ID: 23680, Token: JECT\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 284, Token:  to\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 32, Token: A\n",
      "Token ID: 60, Token: ]\n",
      "\n",
      "\n",
      "Template: Afterwards [A], [B] and [C] went to the [PLACE]. [B] and [C] gave a [OBJECT] to [A]\n",
      "Token ID: 3260, Token: After\n",
      "Token ID: 2017, Token: wards\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 32, Token: A\n",
      "Token ID: 4357, Token: ],\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 33, Token: B\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 290, Token:  and\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 34, Token: C\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 1816, Token:  went\n",
      "Token ID: 284, Token:  to\n",
      "Token ID: 262, Token:  the\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 6489, Token: PL\n",
      "Token ID: 11598, Token: ACE\n",
      "Token ID: 4083, Token: ].\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 33, Token: B\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 290, Token:  and\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 34, Token: C\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 2921, Token:  gave\n",
      "Token ID: 257, Token:  a\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 9864, Token: OB\n",
      "Token ID: 23680, Token: JECT\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 284, Token:  to\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 32, Token: A\n",
      "Token ID: 60, Token: ]\n",
      "\n",
      "\n",
      "Template: When [A], [B] and [C] arrived at the [PLACE], [B] and [C] gave a [OBJECT] to [A]\n",
      "Token ID: 2215, Token: When\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 32, Token: A\n",
      "Token ID: 4357, Token: ],\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 33, Token: B\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 290, Token:  and\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 34, Token: C\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 5284, Token:  arrived\n",
      "Token ID: 379, Token:  at\n",
      "Token ID: 262, Token:  the\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 6489, Token: PL\n",
      "Token ID: 11598, Token: ACE\n",
      "Token ID: 4357, Token: ],\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 33, Token: B\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 290, Token:  and\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 34, Token: C\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 2921, Token:  gave\n",
      "Token ID: 257, Token:  a\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 9864, Token: OB\n",
      "Token ID: 23680, Token: JECT\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 284, Token:  to\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 32, Token: A\n",
      "Token ID: 60, Token: ]\n",
      "\n",
      "\n",
      "Template: Friends [A], [B] and [C] went to the [PLACE]. [B] and [C] gave a [OBJECT] to [A]\n",
      "Token ID: 36705, Token: Friends\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 32, Token: A\n",
      "Token ID: 4357, Token: ],\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 33, Token: B\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 290, Token:  and\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 34, Token: C\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 1816, Token:  went\n",
      "Token ID: 284, Token:  to\n",
      "Token ID: 262, Token:  the\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 6489, Token: PL\n",
      "Token ID: 11598, Token: ACE\n",
      "Token ID: 4083, Token: ].\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 33, Token: B\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 290, Token:  and\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 34, Token: C\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 2921, Token:  gave\n",
      "Token ID: 257, Token:  a\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 9864, Token: OB\n",
      "Token ID: 23680, Token: JECT\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 284, Token:  to\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 32, Token: A\n",
      "Token ID: 60, Token: ]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ABC_TEMPLATES = [\n",
    "    \"Then, [A], [B] and [C] went to the [PLACE]. [B] and [C] gave a [OBJECT] to [A]\",\n",
    "    \"Afterwards [A], [B] and [C] went to the [PLACE]. [B] and [C] gave a [OBJECT] to [A]\",\n",
    "    \"When [A], [B] and [C] arrived at the [PLACE], [B] and [C] gave a [OBJECT] to [A]\",\n",
    "    \"Friends [A], [B] and [C] went to the [PLACE]. [B] and [C] gave a [OBJECT] to [A]\",\n",
    "]\n",
    "for temp in ABC_TEMPLATES:\n",
    "    tokenized = tokenizer_gpt2.encode(temp)\n",
    "    print(f\"Template: {temp}\")\n",
    "    for token in tokenized:\n",
    "        print(f\"Token ID: {token}, Token: {tokenizer_gpt2.decode([token])}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template: Then, [A], [B] and [C] went to the [PLACE]. [B] and [C] gave a [OBJECT] to [A]\n",
      "Token ID: 5872, Token: Then\n",
      "Token ID: 13, Token: ,\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 34, Token: A\n",
      "Token ID: 1092, Token: ],\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 35, Token: B\n",
      "Token ID: 62, Token: ]\n",
      "Token ID: 285, Token:  and\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 36, Token: C\n",
      "Token ID: 62, Token: ]\n",
      "Token ID: 2427, Token:  went\n",
      "Token ID: 281, Token:  to\n",
      "Token ID: 253, Token:  the\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 3859, Token: PL\n",
      "Token ID: 9566, Token: ACE\n",
      "Token ID: 1570, Token: ].\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 35, Token: B\n",
      "Token ID: 62, Token: ]\n",
      "Token ID: 285, Token:  and\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 36, Token: C\n",
      "Token ID: 62, Token: ]\n",
      "Token ID: 3534, Token:  gave\n",
      "Token ID: 247, Token:  a\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 35581, Token: OBJECT\n",
      "Token ID: 62, Token: ]\n",
      "Token ID: 281, Token:  to\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 34, Token: A\n",
      "Token ID: 62, Token: ]\n",
      "\n",
      "\n",
      "Template: Afterwards [A], [B] and [C] went to the [PLACE]. [B] and [C] gave a [OBJECT] to [A]\n",
      "Token ID: 4553, Token: After\n",
      "Token ID: 4515, Token: wards\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 34, Token: A\n",
      "Token ID: 1092, Token: ],\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 35, Token: B\n",
      "Token ID: 62, Token: ]\n",
      "Token ID: 285, Token:  and\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 36, Token: C\n",
      "Token ID: 62, Token: ]\n",
      "Token ID: 2427, Token:  went\n",
      "Token ID: 281, Token:  to\n",
      "Token ID: 253, Token:  the\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 3859, Token: PL\n",
      "Token ID: 9566, Token: ACE\n",
      "Token ID: 1570, Token: ].\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 35, Token: B\n",
      "Token ID: 62, Token: ]\n",
      "Token ID: 285, Token:  and\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 36, Token: C\n",
      "Token ID: 62, Token: ]\n",
      "Token ID: 3534, Token:  gave\n",
      "Token ID: 247, Token:  a\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 35581, Token: OBJECT\n",
      "Token ID: 62, Token: ]\n",
      "Token ID: 281, Token:  to\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 34, Token: A\n",
      "Token ID: 62, Token: ]\n",
      "\n",
      "\n",
      "Template: When [A], [B] and [C] arrived at the [PLACE], [B] and [C] gave a [OBJECT] to [A]\n",
      "Token ID: 3039, Token: When\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 34, Token: A\n",
      "Token ID: 1092, Token: ],\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 35, Token: B\n",
      "Token ID: 62, Token: ]\n",
      "Token ID: 285, Token:  and\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 36, Token: C\n",
      "Token ID: 62, Token: ]\n",
      "Token ID: 7244, Token:  arrived\n",
      "Token ID: 387, Token:  at\n",
      "Token ID: 253, Token:  the\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 3859, Token: PL\n",
      "Token ID: 9566, Token: ACE\n",
      "Token ID: 1092, Token: ],\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 35, Token: B\n",
      "Token ID: 62, Token: ]\n",
      "Token ID: 285, Token:  and\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 36, Token: C\n",
      "Token ID: 62, Token: ]\n",
      "Token ID: 3534, Token:  gave\n",
      "Token ID: 247, Token:  a\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 35581, Token: OBJECT\n",
      "Token ID: 62, Token: ]\n",
      "Token ID: 281, Token:  to\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 34, Token: A\n",
      "Token ID: 62, Token: ]\n",
      "\n",
      "\n",
      "Template: Finally [A], [B] and [C] went to the [PLACE]. [B] and [C] gave a [OBJECT] to [A]\n",
      "Token ID: 10971, Token: Finally\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 34, Token: A\n",
      "Token ID: 1092, Token: ],\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 35, Token: B\n",
      "Token ID: 62, Token: ]\n",
      "Token ID: 285, Token:  and\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 36, Token: C\n",
      "Token ID: 62, Token: ]\n",
      "Token ID: 2427, Token:  went\n",
      "Token ID: 281, Token:  to\n",
      "Token ID: 253, Token:  the\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 3859, Token: PL\n",
      "Token ID: 9566, Token: ACE\n",
      "Token ID: 1570, Token: ].\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 35, Token: B\n",
      "Token ID: 62, Token: ]\n",
      "Token ID: 285, Token:  and\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 36, Token: C\n",
      "Token ID: 62, Token: ]\n",
      "Token ID: 3534, Token:  gave\n",
      "Token ID: 247, Token:  a\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 35581, Token: OBJECT\n",
      "Token ID: 62, Token: ]\n",
      "Token ID: 281, Token:  to\n",
      "Token ID: 544, Token:  [\n",
      "Token ID: 34, Token: A\n",
      "Token ID: 62, Token: ]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ABC_TEMPLATES = [\n",
    "    \"Then, [A], [B] and [C] went to the [PLACE]. [B] and [C] gave a [OBJECT] to [A]\",\n",
    "    \"Afterwards [A], [B] and [C] went to the [PLACE]. [B] and [C] gave a [OBJECT] to [A]\",\n",
    "    \"When [A], [B] and [C] arrived at the [PLACE], [B] and [C] gave a [OBJECT] to [A]\",\n",
    "    \"Finally [A], [B] and [C] went to the [PLACE]. [B] and [C] gave a [OBJECT] to [A]\",\n",
    "]\n",
    "for temp in ABC_TEMPLATES:\n",
    "    tokenized = tokenizer.encode(temp)\n",
    "    print(f\"Template: {temp}\")\n",
    "    for token in tokenized:\n",
    "        print(f\"Token ID: {token}, Token: {tokenizer.decode([token])}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "35\n",
      "Template: Then, [A], [B] and [C] went to the [PLACE]. [B] and [C] gave a [OBJECT] to [A]\n",
      "36\n",
      "35\n",
      "Template: Afterwards [A], [B] and [C] went to the [PLACE]. [B] and [C] gave a [OBJECT] to [A]\n",
      "35\n",
      "34\n",
      "Template: When [A], [B] and [C] arrived at the [PLACE], [B] and [C] gave a [OBJECT] to [A]\n",
      "35\n",
      "34\n",
      "Template: Finally [A], [B] and [C] went to the [PLACE]. [B] and [C] gave a [OBJECT] to [A]\n"
     ]
    }
   ],
   "source": [
    "ABC_TEMPLATES = [\n",
    "    \"Then, [A], [B] and [C] went to the [PLACE]. [B] and [C] gave a [OBJECT] to [A]\",\n",
    "    \"Afterwards [A], [B] and [C] went to the [PLACE]. [B] and [C] gave a [OBJECT] to [A]\",\n",
    "    \"When [A], [B] and [C] arrived at the [PLACE], [B] and [C] gave a [OBJECT] to [A]\",\n",
    "    \"Finally [A], [B] and [C] went to the [PLACE]. [B] and [C] gave a [OBJECT] to [A]\",\n",
    "]\n",
    "for temp in ABC_TEMPLATES:\n",
    "    tokenized = tokenizer.encode(temp)\n",
    "    tokenized_gpt2 = tokenizer_gpt2.encode(temp)\n",
    "    if len(tokenized_gpt2) != len(tokenized):\n",
    "        print(len(tokenized_gpt2))\n",
    "        print(len(tokenized))\n",
    "        print(f\"Template: {temp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template: Then, [B] and [A] went to the [PLACE]. [B] gave a [OBJECT] to [A]\n",
      "29\n",
      "28\n",
      "\n",
      "\n",
      "Template: Then, [B] and [A] had a lot of fun at the [PLACE]. [B] gave a [OBJECT] to [A]\n",
      "33\n",
      "32\n",
      "\n",
      "\n",
      "Template: Then, [B] and [A] were working at the [PLACE]. [B] decided to give a [OBJECT] to [A]\n",
      "32\n",
      "31\n",
      "\n",
      "\n",
      "Template: Then, [B] and [A] were thinking about going to the [PLACE]. [B] wanted to give a [OBJECT] to [A]\n",
      "34\n",
      "33\n",
      "\n",
      "\n",
      "Template: Then, [B] and [A] had a long argument, and afterwards [B] said to [A]\n",
      "24\n",
      "24\n",
      "\n",
      "\n",
      "Template: After [B] and [A] went to the [PLACE], [B] gave a [OBJECT] to [A]\n",
      "28\n",
      "27\n",
      "\n",
      "\n",
      "Template: When [B] and [A] got a [OBJECT] at the [PLACE], [B] decided to give it to [A]\n",
      "31\n",
      "30\n",
      "\n",
      "\n",
      "Template: When [B] and [A] got a [OBJECT] at the [PLACE], [B] decided to give the [OBJECT] to [A]\n",
      "35\n",
      "33\n",
      "\n",
      "\n",
      "Template: While [B] and [A] were working at the [PLACE], [B] gave a [OBJECT] to [A]\n",
      "29\n",
      "28\n",
      "\n",
      "\n",
      "Template: While [B] and [A] were commuting to the [PLACE], [B] gave a [OBJECT] to [A]\n",
      "29\n",
      "28\n",
      "\n",
      "\n",
      "Template: After the lunch, [B] and [A] went to the [PLACE]. [B] gave a [OBJECT] to [A]\n",
      "31\n",
      "30\n",
      "\n",
      "\n",
      "Template: Later, [B] and [A] went to the [PLACE]. [B] gave a [OBJECT] to [A]\n",
      "29\n",
      "28\n",
      "\n",
      "\n",
      "Template: Then, [B] and [A] had a long argument. Afterwards [B] said to [A]\n",
      "23\n",
      "23\n",
      "\n",
      "\n",
      "Template: The [PLACE] [B] and [A] went to had a [OBJECT]. [B] gave it to [A]\n",
      "29\n",
      "28\n",
      "\n",
      "\n",
      "Template: Finally [B] and [A] found a [OBJECT] at the [PLACE]. [B] gave it to [A]\n",
      "29\n",
      "28\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BABA_TEMPLATES = [\n",
    "    \"Then, [B] and [A] went to the [PLACE]. [B] gave a [OBJECT] to [A]\",\n",
    "    \"Then, [B] and [A] had a lot of fun at the [PLACE]. [B] gave a [OBJECT] to [A]\",\n",
    "    \"Then, [B] and [A] were working at the [PLACE]. [B] decided to give a [OBJECT] to [A]\",\n",
    "    \"Then, [B] and [A] were thinking about going to the [PLACE]. [B] wanted to give a [OBJECT] to [A]\",\n",
    "    \"Then, [B] and [A] had a long argument, and afterwards [B] said to [A]\",\n",
    "    \"After [B] and [A] went to the [PLACE], [B] gave a [OBJECT] to [A]\",\n",
    "    \"When [B] and [A] got a [OBJECT] at the [PLACE], [B] decided to give it to [A]\",\n",
    "    \"When [B] and [A] got a [OBJECT] at the [PLACE], [B] decided to give the [OBJECT] to [A]\",\n",
    "    \"While [B] and [A] were working at the [PLACE], [B] gave a [OBJECT] to [A]\",\n",
    "    \"While [B] and [A] were commuting to the [PLACE], [B] gave a [OBJECT] to [A]\",\n",
    "    \"After the lunch, [B] and [A] went to the [PLACE]. [B] gave a [OBJECT] to [A]\",\n",
    "    \"Later, [B] and [A] went to the [PLACE]. [B] gave a [OBJECT] to [A]\",\n",
    "    \"Then, [B] and [A] had a long argument. Afterwards [B] said to [A]\",\n",
    "    \"The [PLACE] [B] and [A] went to had a [OBJECT]. [B] gave it to [A]\",\n",
    "    \"Finally [B] and [A] found a [OBJECT] at the [PLACE]. [B] gave it to [A]\",\n",
    "]\n",
    "for temp in BABA_TEMPLATES:\n",
    "    tokenized_gpt2 = tokenizer_gpt2.encode(temp)\n",
    "    tokenized = tokenizer.encode(temp)\n",
    "    print(f\"Template: {temp}\")\n",
    "    print(len(tokenized_gpt2))\n",
    "    print(len(tokenized))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template: Then, [B] and [A] went to the [PLACE]. [B] gave a [OBJECT] to [A]\n",
      "Token ID: 6423, Token: Then\n",
      "Token ID: 11, Token: ,\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 33, Token: B\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 290, Token:  and\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 32, Token: A\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 1816, Token:  went\n",
      "Token ID: 284, Token:  to\n",
      "Token ID: 262, Token:  the\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 6489, Token: PL\n",
      "Token ID: 11598, Token: ACE\n",
      "Token ID: 4083, Token: ].\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 33, Token: B\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 2921, Token:  gave\n",
      "Token ID: 257, Token:  a\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 9864, Token: OB\n",
      "Token ID: 23680, Token: JECT\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 284, Token:  to\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 32, Token: A\n",
      "Token ID: 60, Token: ]\n",
      "\n",
      "\n",
      "Template: Then, [B] and [A] had a lot of fun at the [PLACE]. [B] gave a [OBJECT] to [A]\n",
      "Token ID: 6423, Token: Then\n",
      "Token ID: 11, Token: ,\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 33, Token: B\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 290, Token:  and\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 32, Token: A\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 550, Token:  had\n",
      "Token ID: 257, Token:  a\n",
      "Token ID: 1256, Token:  lot\n",
      "Token ID: 286, Token:  of\n",
      "Token ID: 1257, Token:  fun\n",
      "Token ID: 379, Token:  at\n",
      "Token ID: 262, Token:  the\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 6489, Token: PL\n",
      "Token ID: 11598, Token: ACE\n",
      "Token ID: 4083, Token: ].\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 33, Token: B\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 2921, Token:  gave\n",
      "Token ID: 257, Token:  a\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 9864, Token: OB\n",
      "Token ID: 23680, Token: JECT\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 284, Token:  to\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 32, Token: A\n",
      "Token ID: 60, Token: ]\n",
      "\n",
      "\n",
      "Template: Then, [B] and [A] were working at the [PLACE]. [B] decided to give a [OBJECT] to [A]\n",
      "Token ID: 6423, Token: Then\n",
      "Token ID: 11, Token: ,\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 33, Token: B\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 290, Token:  and\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 32, Token: A\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 547, Token:  were\n",
      "Token ID: 1762, Token:  working\n",
      "Token ID: 379, Token:  at\n",
      "Token ID: 262, Token:  the\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 6489, Token: PL\n",
      "Token ID: 11598, Token: ACE\n",
      "Token ID: 4083, Token: ].\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 33, Token: B\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 3066, Token:  decided\n",
      "Token ID: 284, Token:  to\n",
      "Token ID: 1577, Token:  give\n",
      "Token ID: 257, Token:  a\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 9864, Token: OB\n",
      "Token ID: 23680, Token: JECT\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 284, Token:  to\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 32, Token: A\n",
      "Token ID: 60, Token: ]\n",
      "\n",
      "\n",
      "Template: Then, [B] and [A] were thinking about going to the [PLACE]. [B] wanted to give a [OBJECT] to [A]\n",
      "Token ID: 6423, Token: Then\n",
      "Token ID: 11, Token: ,\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 33, Token: B\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 290, Token:  and\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 32, Token: A\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 547, Token:  were\n",
      "Token ID: 3612, Token:  thinking\n",
      "Token ID: 546, Token:  about\n",
      "Token ID: 1016, Token:  going\n",
      "Token ID: 284, Token:  to\n",
      "Token ID: 262, Token:  the\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 6489, Token: PL\n",
      "Token ID: 11598, Token: ACE\n",
      "Token ID: 4083, Token: ].\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 33, Token: B\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 2227, Token:  wanted\n",
      "Token ID: 284, Token:  to\n",
      "Token ID: 1577, Token:  give\n",
      "Token ID: 257, Token:  a\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 9864, Token: OB\n",
      "Token ID: 23680, Token: JECT\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 284, Token:  to\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 32, Token: A\n",
      "Token ID: 60, Token: ]\n",
      "\n",
      "\n",
      "Template: Then, [B] and [A] had a long argument, and afterwards [B] said to [A]\n",
      "Token ID: 6423, Token: Then\n",
      "Token ID: 11, Token: ,\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 33, Token: B\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 290, Token:  and\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 32, Token: A\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 550, Token:  had\n",
      "Token ID: 257, Token:  a\n",
      "Token ID: 890, Token:  long\n",
      "Token ID: 4578, Token:  argument\n",
      "Token ID: 11, Token: ,\n",
      "Token ID: 290, Token:  and\n",
      "Token ID: 12979, Token:  afterwards\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 33, Token: B\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 531, Token:  said\n",
      "Token ID: 284, Token:  to\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 32, Token: A\n",
      "Token ID: 60, Token: ]\n",
      "\n",
      "\n",
      "Template: After [B] and [A] went to the [PLACE], [B] gave a [OBJECT] to [A]\n",
      "Token ID: 3260, Token: After\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 33, Token: B\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 290, Token:  and\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 32, Token: A\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 1816, Token:  went\n",
      "Token ID: 284, Token:  to\n",
      "Token ID: 262, Token:  the\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 6489, Token: PL\n",
      "Token ID: 11598, Token: ACE\n",
      "Token ID: 4357, Token: ],\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 33, Token: B\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 2921, Token:  gave\n",
      "Token ID: 257, Token:  a\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 9864, Token: OB\n",
      "Token ID: 23680, Token: JECT\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 284, Token:  to\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 32, Token: A\n",
      "Token ID: 60, Token: ]\n",
      "\n",
      "\n",
      "Template: When [B] and [A] got a [OBJECT] at the [PLACE], [B] decided to give it to [A]\n",
      "Token ID: 2215, Token: When\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 33, Token: B\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 290, Token:  and\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 32, Token: A\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 1392, Token:  got\n",
      "Token ID: 257, Token:  a\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 9864, Token: OB\n",
      "Token ID: 23680, Token: JECT\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 379, Token:  at\n",
      "Token ID: 262, Token:  the\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 6489, Token: PL\n",
      "Token ID: 11598, Token: ACE\n",
      "Token ID: 4357, Token: ],\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 33, Token: B\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 3066, Token:  decided\n",
      "Token ID: 284, Token:  to\n",
      "Token ID: 1577, Token:  give\n",
      "Token ID: 340, Token:  it\n",
      "Token ID: 284, Token:  to\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 32, Token: A\n",
      "Token ID: 60, Token: ]\n",
      "\n",
      "\n",
      "Template: When [B] and [A] got a [OBJECT] at the [PLACE], [B] decided to give the [OBJECT] to [A]\n",
      "Token ID: 2215, Token: When\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 33, Token: B\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 290, Token:  and\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 32, Token: A\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 1392, Token:  got\n",
      "Token ID: 257, Token:  a\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 9864, Token: OB\n",
      "Token ID: 23680, Token: JECT\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 379, Token:  at\n",
      "Token ID: 262, Token:  the\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 6489, Token: PL\n",
      "Token ID: 11598, Token: ACE\n",
      "Token ID: 4357, Token: ],\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 33, Token: B\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 3066, Token:  decided\n",
      "Token ID: 284, Token:  to\n",
      "Token ID: 1577, Token:  give\n",
      "Token ID: 262, Token:  the\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 9864, Token: OB\n",
      "Token ID: 23680, Token: JECT\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 284, Token:  to\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 32, Token: A\n",
      "Token ID: 60, Token: ]\n",
      "\n",
      "\n",
      "Template: While [B] and [A] were working at the [PLACE], [B] gave a [OBJECT] to [A]\n",
      "Token ID: 3633, Token: While\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 33, Token: B\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 290, Token:  and\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 32, Token: A\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 547, Token:  were\n",
      "Token ID: 1762, Token:  working\n",
      "Token ID: 379, Token:  at\n",
      "Token ID: 262, Token:  the\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 6489, Token: PL\n",
      "Token ID: 11598, Token: ACE\n",
      "Token ID: 4357, Token: ],\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 33, Token: B\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 2921, Token:  gave\n",
      "Token ID: 257, Token:  a\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 9864, Token: OB\n",
      "Token ID: 23680, Token: JECT\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 284, Token:  to\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 32, Token: A\n",
      "Token ID: 60, Token: ]\n",
      "\n",
      "\n",
      "Template: While [B] and [A] were commuting to the [PLACE], [B] gave a [OBJECT] to [A]\n",
      "Token ID: 3633, Token: While\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 33, Token: B\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 290, Token:  and\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 32, Token: A\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 547, Token:  were\n",
      "Token ID: 45309, Token:  commuting\n",
      "Token ID: 284, Token:  to\n",
      "Token ID: 262, Token:  the\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 6489, Token: PL\n",
      "Token ID: 11598, Token: ACE\n",
      "Token ID: 4357, Token: ],\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 33, Token: B\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 2921, Token:  gave\n",
      "Token ID: 257, Token:  a\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 9864, Token: OB\n",
      "Token ID: 23680, Token: JECT\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 284, Token:  to\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 32, Token: A\n",
      "Token ID: 60, Token: ]\n",
      "\n",
      "\n",
      "Template: After the lunch, [B] and [A] went to the [PLACE]. [B] gave a [OBJECT] to [A]\n",
      "Token ID: 3260, Token: After\n",
      "Token ID: 262, Token:  the\n",
      "Token ID: 9965, Token:  lunch\n",
      "Token ID: 11, Token: ,\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 33, Token: B\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 290, Token:  and\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 32, Token: A\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 1816, Token:  went\n",
      "Token ID: 284, Token:  to\n",
      "Token ID: 262, Token:  the\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 6489, Token: PL\n",
      "Token ID: 11598, Token: ACE\n",
      "Token ID: 4083, Token: ].\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 33, Token: B\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 2921, Token:  gave\n",
      "Token ID: 257, Token:  a\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 9864, Token: OB\n",
      "Token ID: 23680, Token: JECT\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 284, Token:  to\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 32, Token: A\n",
      "Token ID: 60, Token: ]\n",
      "\n",
      "\n",
      "Template: Later, [B] and [A] went to the [PLACE]. [B] gave a [OBJECT] to [A]\n",
      "Token ID: 18602, Token: Later\n",
      "Token ID: 11, Token: ,\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 33, Token: B\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 290, Token:  and\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 32, Token: A\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 1816, Token:  went\n",
      "Token ID: 284, Token:  to\n",
      "Token ID: 262, Token:  the\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 6489, Token: PL\n",
      "Token ID: 11598, Token: ACE\n",
      "Token ID: 4083, Token: ].\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 33, Token: B\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 2921, Token:  gave\n",
      "Token ID: 257, Token:  a\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 9864, Token: OB\n",
      "Token ID: 23680, Token: JECT\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 284, Token:  to\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 32, Token: A\n",
      "Token ID: 60, Token: ]\n",
      "\n",
      "\n",
      "Template: Then, [B] and [A] had a long argument. Afterwards [B] said to [A]\n",
      "Token ID: 6423, Token: Then\n",
      "Token ID: 11, Token: ,\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 33, Token: B\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 290, Token:  and\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 32, Token: A\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 550, Token:  had\n",
      "Token ID: 257, Token:  a\n",
      "Token ID: 890, Token:  long\n",
      "Token ID: 4578, Token:  argument\n",
      "Token ID: 13, Token: .\n",
      "Token ID: 39063, Token:  Afterwards\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 33, Token: B\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 531, Token:  said\n",
      "Token ID: 284, Token:  to\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 32, Token: A\n",
      "Token ID: 60, Token: ]\n",
      "\n",
      "\n",
      "Template: The [PLACE] [B] and [A] went to had a [OBJECT]. [B] gave it to [A]\n",
      "Token ID: 464, Token: The\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 6489, Token: PL\n",
      "Token ID: 11598, Token: ACE\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 33, Token: B\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 290, Token:  and\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 32, Token: A\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 1816, Token:  went\n",
      "Token ID: 284, Token:  to\n",
      "Token ID: 550, Token:  had\n",
      "Token ID: 257, Token:  a\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 9864, Token: OB\n",
      "Token ID: 23680, Token: JECT\n",
      "Token ID: 4083, Token: ].\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 33, Token: B\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 2921, Token:  gave\n",
      "Token ID: 340, Token:  it\n",
      "Token ID: 284, Token:  to\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 32, Token: A\n",
      "Token ID: 60, Token: ]\n",
      "\n",
      "\n",
      "Template: Finally [B] and [A] found a [OBJECT] at the [PLACE]. [B] gave it to [A]\n",
      "Token ID: 11158, Token: Finally\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 33, Token: B\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 290, Token:  and\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 32, Token: A\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 1043, Token:  found\n",
      "Token ID: 257, Token:  a\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 9864, Token: OB\n",
      "Token ID: 23680, Token: JECT\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 379, Token:  at\n",
      "Token ID: 262, Token:  the\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 6489, Token: PL\n",
      "Token ID: 11598, Token: ACE\n",
      "Token ID: 4083, Token: ].\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 33, Token: B\n",
      "Token ID: 60, Token: ]\n",
      "Token ID: 2921, Token:  gave\n",
      "Token ID: 340, Token:  it\n",
      "Token ID: 284, Token:  to\n",
      "Token ID: 685, Token:  [\n",
      "Token ID: 32, Token: A\n",
      "Token ID: 60, Token: ]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BABA_TEMPLATES = [\n",
    "    \"Then, [B] and [A] went to the [PLACE]. [B] gave a [OBJECT] to [A]\",\n",
    "    \"Then, [B] and [A] had a lot of fun at the [PLACE]. [B] gave a [OBJECT] to [A]\",\n",
    "    \"Then, [B] and [A] were working at the [PLACE]. [B] decided to give a [OBJECT] to [A]\",\n",
    "    \"Then, [B] and [A] were thinking about going to the [PLACE]. [B] wanted to give a [OBJECT] to [A]\",\n",
    "    \"Then, [B] and [A] had a long argument, and afterwards [B] said to [A]\",\n",
    "    \"After [B] and [A] went to the [PLACE], [B] gave a [OBJECT] to [A]\",\n",
    "    \"When [B] and [A] got a [OBJECT] at the [PLACE], [B] decided to give it to [A]\",\n",
    "    \"When [B] and [A] got a [OBJECT] at the [PLACE], [B] decided to give the [OBJECT] to [A]\",\n",
    "    \"While [B] and [A] were working at the [PLACE], [B] gave a [OBJECT] to [A]\",\n",
    "    \"While [B] and [A] were commuting to the [PLACE], [B] gave a [OBJECT] to [A]\",\n",
    "    \"After the lunch, [B] and [A] went to the [PLACE]. [B] gave a [OBJECT] to [A]\",\n",
    "    \"Later, [B] and [A] went to the [PLACE]. [B] gave a [OBJECT] to [A]\",\n",
    "    \"Then, [B] and [A] had a long argument. Afterwards [B] said to [A]\",\n",
    "    \"The [PLACE] [B] and [A] went to had a [OBJECT]. [B] gave it to [A]\",\n",
    "    \"Finally [B] and [A] found a [OBJECT] at the [PLACE]. [B] gave it to [A]\",\n",
    "]\n",
    "for temp in BABA_TEMPLATES:\n",
    "    tokenized = tokenizer_gpt2.encode(temp)\n",
    "    print(f\"Template: {temp}\")\n",
    "    for token in tokenized:\n",
    "        print(f\"Token ID: {token}, Token: {tokenizer_gpt2.decode([token])}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing names that are too long for pythia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brittany\n",
      "Danielle\n",
      "Kimberly\n",
      "Tiffany\n",
      "Samantha\n",
      "Dustin\n",
      "Erica\n",
      "Kristen\n",
      "Vanessa\n",
      "Courtney\n",
      "Alicia\n"
     ]
    }
   ],
   "source": [
    "for name in NAMES:\n",
    "    #if length is > 1, we need to print the name\n",
    "    if len(tokenizer.encode(\" \" + name)) > 1:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_names = [\"Brittany\", \"Danielle\", \"Kimberly\", \"Tiffany\", \"Samantha\", \"Dustin\", \n",
    "             \"Erica\", \"Kristen\", \"Vanessa\", \"Courtney\", \"Alicia\"]\n",
    "len(bad_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_names = [\"Helen\", \"Bill\", \"Luke\", \"Mason\", \"Douglas\", \"Finn\", \"Susan\", \"Sophie\", \"Billy\", \"Bob\", \"Albert\"]\n",
    "len(new_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAMES = [\n",
    "    \"Michael\",\n",
    "    \"Christopher\",\n",
    "    \"Jessica\",\n",
    "    \"Matthew\",\n",
    "    \"Ashley\",\n",
    "    \"Jennifer\",\n",
    "    \"Joshua\",\n",
    "    \"Amanda\",\n",
    "    \"Daniel\",\n",
    "    \"David\",\n",
    "    \"James\",\n",
    "    \"Robert\",\n",
    "    \"John\",\n",
    "    \"Joseph\",\n",
    "    \"Andrew\",\n",
    "    \"Ryan\",\n",
    "    \"Brandon\",\n",
    "    \"Jason\",\n",
    "    \"Justin\",\n",
    "    \"Sarah\",\n",
    "    \"William\",\n",
    "    \"Jonathan\",\n",
    "    \"Stephanie\",\n",
    "    \"Brian\",\n",
    "    \"Nicole\",\n",
    "    \"Nicholas\",\n",
    "    \"Anthony\",\n",
    "    \"Heather\",\n",
    "    \"Eric\",\n",
    "    \"Elizabeth\",\n",
    "    \"Adam\",\n",
    "    \"Megan\",\n",
    "    \"Melissa\",\n",
    "    \"Kevin\",\n",
    "    \"Steven\",\n",
    "    \"Thomas\",\n",
    "    \"Timothy\",\n",
    "    \"Christina\",\n",
    "    \"Kyle\",\n",
    "    \"Rachel\",\n",
    "    \"Laura\",\n",
    "    \"Lauren\",\n",
    "    \"Amber\",\n",
    "    \"Brittany\",\n",
    "    \"Danielle\",\n",
    "    \"Richard\",\n",
    "    \"Kimberly\",\n",
    "    \"Jeffrey\",\n",
    "    \"Amy\",\n",
    "    \"Crystal\",\n",
    "    \"Michelle\",\n",
    "    \"Tiffany\",\n",
    "    \"Jeremy\",\n",
    "    \"Benjamin\",\n",
    "    \"Mark\",\n",
    "    \"Emily\",\n",
    "    \"Aaron\",\n",
    "    \"Charles\",\n",
    "    \"Rebecca\",\n",
    "    \"Jacob\",\n",
    "    \"Stephen\",\n",
    "    \"Patrick\",\n",
    "    \"Sean\",\n",
    "    \"Erin\",\n",
    "    \"Jamie\",\n",
    "    \"Kelly\",\n",
    "    \"Samantha\",\n",
    "    \"Nathan\",\n",
    "    \"Sara\",\n",
    "    \"Dustin\",\n",
    "    \"Paul\",\n",
    "    \"Angela\",\n",
    "    \"Tyler\",\n",
    "    \"Scott\",\n",
    "    \"Katherine\",\n",
    "    \"Andrea\",\n",
    "    \"Gregory\",\n",
    "    \"Erica\",\n",
    "    \"Mary\",\n",
    "    \"Travis\",\n",
    "    \"Lisa\",\n",
    "    \"Kenneth\",\n",
    "    \"Bryan\",\n",
    "    \"Lindsey\",\n",
    "    \"Kristen\",\n",
    "    \"Jose\",\n",
    "    \"Alexander\",\n",
    "    \"Jesse\",\n",
    "    \"Katie\",\n",
    "    \"Lindsay\",\n",
    "    \"Shannon\",\n",
    "    \"Vanessa\",\n",
    "    \"Courtney\",\n",
    "    \"Christine\",\n",
    "    \"Alicia\",\n",
    "    \"Cody\",\n",
    "    \"Allison\",\n",
    "    \"Bradley\",\n",
    "    \"Samuel\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n",
      "110\n",
      "99\n",
      "NAMES = [\n",
      "    \"Michael\",\n",
      "    \"Christopher\",\n",
      "    \"Jessica\",\n",
      "    \"Matthew\",\n",
      "    \"Ashley\",\n",
      "    \"Jennifer\",\n",
      "    \"Joshua\",\n",
      "    \"Amanda\",\n",
      "    \"Daniel\",\n",
      "    \"David\",\n",
      "    \"James\",\n",
      "    \"Robert\",\n",
      "    \"John\",\n",
      "    \"Joseph\",\n",
      "    \"Andrew\",\n",
      "    \"Ryan\",\n",
      "    \"Brandon\",\n",
      "    \"Jason\",\n",
      "    \"Justin\",\n",
      "    \"Sarah\",\n",
      "    \"William\",\n",
      "    \"Jonathan\",\n",
      "    \"Stephanie\",\n",
      "    \"Brian\",\n",
      "    \"Nicole\",\n",
      "    \"Nicholas\",\n",
      "    \"Anthony\",\n",
      "    \"Heather\",\n",
      "    \"Eric\",\n",
      "    \"Elizabeth\",\n",
      "    \"Adam\",\n",
      "    \"Megan\",\n",
      "    \"Melissa\",\n",
      "    \"Kevin\",\n",
      "    \"Steven\",\n",
      "    \"Thomas\",\n",
      "    \"Timothy\",\n",
      "    \"Christina\",\n",
      "    \"Kyle\",\n",
      "    \"Rachel\",\n",
      "    \"Laura\",\n",
      "    \"Lauren\",\n",
      "    \"Amber\",\n",
      "    \"Richard\",\n",
      "    \"Jeffrey\",\n",
      "    \"Amy\",\n",
      "    \"Crystal\",\n",
      "    \"Michelle\",\n",
      "    \"Jeremy\",\n",
      "    \"Benjamin\",\n",
      "    \"Mark\",\n",
      "    \"Emily\",\n",
      "    \"Aaron\",\n",
      "    \"Charles\",\n",
      "    \"Rebecca\",\n",
      "    \"Jacob\",\n",
      "    \"Stephen\",\n",
      "    \"Patrick\",\n",
      "    \"Sean\",\n",
      "    \"Erin\",\n",
      "    \"Jamie\",\n",
      "    \"Kelly\",\n",
      "    \"Nathan\",\n",
      "    \"Sara\",\n",
      "    \"Paul\",\n",
      "    \"Angela\",\n",
      "    \"Tyler\",\n",
      "    \"Scott\",\n",
      "    \"Katherine\",\n",
      "    \"Andrea\",\n",
      "    \"Gregory\",\n",
      "    \"Mary\",\n",
      "    \"Travis\",\n",
      "    \"Lisa\",\n",
      "    \"Kenneth\",\n",
      "    \"Bryan\",\n",
      "    \"Lindsey\",\n",
      "    \"Jose\",\n",
      "    \"Alexander\",\n",
      "    \"Jesse\",\n",
      "    \"Katie\",\n",
      "    \"Lindsay\",\n",
      "    \"Shannon\",\n",
      "    \"Christine\",\n",
      "    \"Cody\",\n",
      "    \"Allison\",\n",
      "    \"Bradley\",\n",
      "    \"Samuel\",\n",
      "    \"Helen\",\n",
      "    \"Bill\",\n",
      "    \"Luke\",\n",
      "    \"Mason\",\n",
      "    \"Douglas\",\n",
      "    \"Finn\",\n",
      "    \"Susan\",\n",
      "    \"Sophie\",\n",
      "    \"Billy\",\n",
      "    \"Bob\",\n",
      "    \"Albert\",\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(len(NAMES))\n",
    "NAMES.extend(new_names)\n",
    "print(len(NAMES))\n",
    "for bad_name in bad_names:\n",
    "    NAMES.remove(bad_name)\n",
    "print(len(NAMES))\n",
    "#printing list\n",
    "print(\"NAMES = [\") \n",
    "for name in NAMES:\n",
    "    print(\"    \\\"\" + name + \"\\\",\")\n",
    "print(\"]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NAMES = [\n",
    "    \"Michael\",\n",
    "    \"Christopher\",\n",
    "    \"Jessica\",\n",
    "    \"Matthew\",\n",
    "    \"Ashley\",\n",
    "    \"Jennifer\",\n",
    "    \"Joshua\",\n",
    "    \"Amanda\",\n",
    "    \"Daniel\",\n",
    "    \"David\",\n",
    "    \"James\",\n",
    "    \"Robert\",\n",
    "    \"John\",\n",
    "    \"Joseph\",\n",
    "    \"Andrew\",\n",
    "    \"Ryan\",\n",
    "    \"Brandon\",\n",
    "    \"Jason\",\n",
    "    \"Justin\",\n",
    "    \"Sarah\",\n",
    "    \"William\",\n",
    "    \"Jonathan\",\n",
    "    \"Stephanie\",\n",
    "    \"Brian\",\n",
    "    \"Nicole\",\n",
    "    \"Nicholas\",\n",
    "    \"Anthony\",\n",
    "    \"Heather\",\n",
    "    \"Eric\",\n",
    "    \"Elizabeth\",\n",
    "    \"Adam\",\n",
    "    \"Megan\",\n",
    "    \"Melissa\",\n",
    "    \"Kevin\",\n",
    "    \"Steven\",\n",
    "    \"Thomas\",\n",
    "    \"Timothy\",\n",
    "    \"Christina\",\n",
    "    \"Kyle\",\n",
    "    \"Rachel\",\n",
    "    \"Laura\",\n",
    "    \"Lauren\",\n",
    "    \"Amber\",\n",
    "    \"Richard\",\n",
    "    \"Jeffrey\",\n",
    "    \"Amy\",\n",
    "    \"Crystal\",\n",
    "    \"Michelle\",\n",
    "    \"Jeremy\",\n",
    "    \"Benjamin\",\n",
    "    \"Mark\",\n",
    "    \"Emily\",\n",
    "    \"Aaron\",\n",
    "    \"Charles\",\n",
    "    \"Rebecca\",\n",
    "    \"Jacob\",\n",
    "    \"Stephen\",\n",
    "    \"Patrick\",\n",
    "    \"Sean\",\n",
    "    \"Erin\",\n",
    "    \"Jamie\",\n",
    "    \"Kelly\",\n",
    "    \"Nathan\",\n",
    "    \"Sara\",\n",
    "    \"Paul\",\n",
    "    \"Angela\",\n",
    "    \"Tyler\",\n",
    "    \"Scott\",\n",
    "    \"Katherine\",\n",
    "    \"Andrea\",\n",
    "    \"Gregory\",\n",
    "    \"Mary\",\n",
    "    \"Travis\",\n",
    "    \"Lisa\",\n",
    "    \"Kenneth\",\n",
    "    \"Bryan\",\n",
    "    \"Lindsey\",\n",
    "    \"Jose\",\n",
    "    \"Alexander\",\n",
    "    \"Jesse\",\n",
    "    \"Katie\",\n",
    "    \"Lindsay\",\n",
    "    \"Shannon\",\n",
    "    \"Christine\",\n",
    "    \"Cody\",\n",
    "    \"Allison\",\n",
    "    \"Bradley\",\n",
    "    \"Samuel\",\n",
    "    \"Helen\",\n",
    "    \"Bill\",\n",
    "    \"Luke\",\n",
    "    \"Mason\",\n",
    "    \"Douglas\",\n",
    "    \"Finn\",\n",
    "    \"Susan\",\n",
    "    \"Sophie\",\n",
    "    \"Billy\",\n",
    "    \"Bob\",\n",
    "    \"Albert\",\n",
    "]\n",
    "\n",
    "for name in NAMES:\n",
    "    #if length is > 1, we need to print the name\n",
    "    if len(tokenizer.encode(\" \" + name)) > 1:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in new_names:\n",
    "    if(name in NAMES):\n",
    "        print(name)\n",
    "    if(len(tokenizer.encode(\" \" + name)) > 1):\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "[18252]\n"
     ]
    }
   ],
   "source": [
    "new_name = \"Albert\"\n",
    "print(new_name in NAMES)\n",
    "print(tokenizer.encode(\" \" + new_name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Animals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " tried\n",
      " said\n",
      " decided\n",
      " wanted\n",
      " gave\n"
     ]
    }
   ],
   "source": [
    "for animal in VERBS:\n",
    "    if len(tokenizer.encode(\" \" + animal)) > 1:\n",
    "        print(animal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAMES = [\n",
    "    \"Michael\",\n",
    "    \"Christopher\",\n",
    "    \"Jessica\",\n",
    "    \"Matthew\",\n",
    "    \"Ashley\",\n",
    "    \"Jennifer\",\n",
    "    \"Joshua\",\n",
    "    \"Amanda\",\n",
    "    \"Daniel\",\n",
    "    \"David\",\n",
    "    \"James\",\n",
    "    \"Robert\",\n",
    "    \"John\",\n",
    "    \"Joseph\",\n",
    "    \"Andrew\",\n",
    "    \"Ryan\",\n",
    "    \"Brandon\",\n",
    "    \"Jason\",\n",
    "    \"Justin\",\n",
    "    \"Sarah\",\n",
    "    \"William\",\n",
    "    \"Jonathan\",\n",
    "    \"Stephanie\",\n",
    "    \"Brian\",\n",
    "    \"Nicole\",\n",
    "    \"Nicholas\",\n",
    "    \"Anthony\",\n",
    "    \"Heather\",\n",
    "    \"Eric\",\n",
    "    \"Elizabeth\",\n",
    "    \"Adam\",\n",
    "    \"Megan\",\n",
    "    \"Melissa\",\n",
    "    \"Kevin\",\n",
    "    \"Steven\",\n",
    "    \"Thomas\",\n",
    "    \"Timothy\",\n",
    "    \"Christina\",\n",
    "    \"Kyle\",\n",
    "    \"Rachel\",\n",
    "    \"Laura\",\n",
    "    \"Lauren\",\n",
    "    \"Amber\",\n",
    "    \"Richard\",\n",
    "    \"Jeffrey\",\n",
    "    \"Amy\",\n",
    "    \"Crystal\",\n",
    "    \"Michelle\",\n",
    "    \"Jeremy\",\n",
    "    \"Benjamin\",\n",
    "    \"Mark\",\n",
    "    \"Emily\",\n",
    "    \"Aaron\",\n",
    "    \"Charles\",\n",
    "    \"Rebecca\",\n",
    "    \"Jacob\",\n",
    "    \"Stephen\",\n",
    "    \"Patrick\",\n",
    "    \"Sean\",\n",
    "    \"Erin\",\n",
    "    \"Jamie\",\n",
    "    \"Kelly\",\n",
    "    \"Nathan\",\n",
    "    \"Sara\",\n",
    "    \"Paul\",\n",
    "    \"Angela\",\n",
    "    \"Tyler\",\n",
    "    \"Scott\",\n",
    "    \"Katherine\",\n",
    "    \"Andrea\",\n",
    "    \"Gregory\",\n",
    "    \"Mary\",\n",
    "    \"Travis\",\n",
    "    \"Lisa\",\n",
    "    \"Kenneth\",\n",
    "    \"Bryan\",\n",
    "    \"Lindsey\",\n",
    "    \"Jose\",\n",
    "    \"Alexander\",\n",
    "    \"Jesse\",\n",
    "    \"Katie\",\n",
    "    \"Lindsay\",\n",
    "    \"Shannon\",\n",
    "    \"Christine\",\n",
    "    \"Cody\",\n",
    "    \"Allison\",\n",
    "    \"Bradley\",\n",
    "    \"Samuel\",\n",
    "    \"Helen\",\n",
    "    \"Bill\",\n",
    "    \"Luke\",\n",
    "    \"Mason\",\n",
    "    \"Douglas\",\n",
    "    \"Finn\",\n",
    "    \"Susan\",\n",
    "    \"Sophie\",\n",
    "    \"Billy\",\n",
    "    \"Bob\",\n",
    "    \"Albert\",\n",
    "]\n",
    "\n",
    "ABC_TEMPLATES = [\n",
    "    \"Then, [A], [B] and [C] went to the [PLACE]. [B] and [C] gave a [OBJECT] to [A]\",\n",
    "    \"Afterwards [A], [B] and [C] went to the [PLACE]. [B] and [C] gave a [OBJECT] to [A]\",\n",
    "    \"When [A], [B] and [C] arrived at the [PLACE], [B] and [C] gave a [OBJECT] to [A]\",\n",
    "    \"Finally [A], [B] and [C] went to the [PLACE]. [B] and [C] gave a [OBJECT] to [A]\",\n",
    "]\n",
    "\n",
    "BAC_TEMPLATES = [\n",
    "    template.replace(\"[B]\", \"[A]\", 1).replace(\"[A]\", \"[B]\", 1)\n",
    "    for template in ABC_TEMPLATES\n",
    "]\n",
    "\n",
    "BABA_TEMPLATES = [\n",
    "    \"Then, [B] and [A] went to the [PLACE]. [B] gave a [OBJECT] to [A]\",\n",
    "    \"Then, [B] and [A] had a lot of fun at the [PLACE]. [B] gave a [OBJECT] to [A]\",\n",
    "    \"Then, [B] and [A] were working at the [PLACE]. [B] decided to give a [OBJECT] to [A]\",\n",
    "    \"Then, [B] and [A] were thinking about going to the [PLACE]. [B] wanted to give a [OBJECT] to [A]\",\n",
    "    \"Then, [B] and [A] had a long argument, and afterwards [B] said to [A]\",\n",
    "    \"After [B] and [A] went to the [PLACE], [B] gave a [OBJECT] to [A]\",\n",
    "    \"When [B] and [A] got a [OBJECT] at the [PLACE], [B] decided to give it to [A]\",\n",
    "    \"When [B] and [A] got a [OBJECT] at the [PLACE], [B] decided to give the [OBJECT] to [A]\",\n",
    "    \"While [B] and [A] were working at the [PLACE], [B] gave a [OBJECT] to [A]\",\n",
    "    \"While [B] and [A] were commuting to the [PLACE], [B] gave a [OBJECT] to [A]\",\n",
    "    \"After the lunch, [B] and [A] went to the [PLACE]. [B] gave a [OBJECT] to [A]\",\n",
    "    \"Later, [B] and [A] went to the [PLACE]. [B] gave a [OBJECT] to [A]\",\n",
    "    \"Then, [B] and [A] had a long argument. Afterwards [B] said to [A]\",\n",
    "    \"The [PLACE] [B] and [A] went to had a [OBJECT]. [B] gave it to [A]\",\n",
    "    \"Finally [B] and [A] found a [OBJECT] at the [PLACE]. [B] gave it to [A]\",\n",
    "]\n",
    "\n",
    "BABA_LONG_TEMPLATES = [\n",
    "    \"Then in the morning, [B] and [A] went to the [PLACE]. [B] gave a [OBJECT] to [A]\",\n",
    "    \"Then in the morning, [B] and [A] had a lot of fun at the [PLACE]. [B] gave a [OBJECT] to [A]\",\n",
    "    \"Then in the morning, [B] and [A] were working at the [PLACE]. [B] decided to give a [OBJECT] to [A]\",\n",
    "    \"Then in the morning, [B] and [A] were thinking about going to the [PLACE]. [B] wanted to give a [OBJECT] to [A]\",\n",
    "    \"Then in the morning, [B] and [A] had a long argument, and afterwards [B] said to [A]\",\n",
    "    \"After taking a long break [B] and [A] went to the [PLACE], [B] gave a [OBJECT] to [A]\",\n",
    "    \"When soon afterwards [B] and [A] got a [OBJECT] at the [PLACE], [B] decided to give it to [A]\",\n",
    "    \"When soon afterwards [B] and [A] got a [OBJECT] at the [PLACE], [B] decided to give the [OBJECT] to [A]\",\n",
    "    \"While spending time together [B] and [A] were working at the [PLACE], [B] gave a [OBJECT] to [A]\",\n",
    "    \"While spending time together [B] and [A] were commuting to the [PLACE], [B] gave a [OBJECT] to [A]\",\n",
    "    \"After the lunch in the afternoon, [B] and [A] went to the [PLACE]. [B] gave a [OBJECT] to [A]\",\n",
    "    \"Afterwards, while spending time together [B] and [A] went to the [PLACE]. [B] gave a [OBJECT] to [A]\",\n",
    "    \"Then in the morning afterwards, [B] and [A] had a long argument. Afterwards [B] said to [A]\",\n",
    "    \"The local big [PLACE] [B] and [A] went to had a [OBJECT]. [B] gave it to [A]\",\n",
    "    \"Friends separated at birth [B] and [A] found a [OBJECT] at the [PLACE]. [B] gave it to [A]\",\n",
    "]\n",
    "\n",
    "BABA_LATE_IOS = [\n",
    "    \"Then, [B] and [A] went to the [PLACE]. [B] gave a [OBJECT] to [A]\",\n",
    "    \"Then, [B] and [A] had a lot of fun at the [PLACE]. [B] gave a [OBJECT] to [A]\",\n",
    "    \"Then, [B] and [A] were working at the [PLACE]. [B] decided to give a [OBJECT] to [A]\",\n",
    "    \"Then, [B] and [A] were thinking about going to the [PLACE]. [B] wanted to give a [OBJECT] to [A]\",\n",
    "    \"Then, [B] and [A] had a long argument and after that [B] said to [A]\",\n",
    "    \"After the lunch, [B] and [A] went to the [PLACE]. [B] gave a [OBJECT] to [A]\",\n",
    "    \"Afterwards, [B] and [A] went to the [PLACE]. [B] gave a [OBJECT] to [A]\",\n",
    "    \"Then, [B] and [A] had a long argument. Afterwards [B] said to [A]\",\n",
    "]\n",
    "\n",
    "BABA_EARLY_IOS = [\n",
    "    \"Then [B] and [A] went to the [PLACE], and [B] gave a [OBJECT] to [A]\",\n",
    "    \"Then [B] and [A] had a lot of fun at the [PLACE], and [B] gave a [OBJECT] to [A]\",\n",
    "    \"Then [B] and [A] were working at the [PLACE], and [B] decided to give a [OBJECT] to [A]\",\n",
    "    \"Then [B] and [A] were thinking about going to the [PLACE], and [B] wanted to give a [OBJECT] to [A]\",\n",
    "    \"Then [B] and [A] had a long argument, and after that [B] said to [A]\",\n",
    "    \"After the lunch [B] and [A] went to the [PLACE], and [B] gave a [OBJECT] to [A]\",\n",
    "    \"Afterwards [B] and [A] went to the [PLACE], and [B] gave a [OBJECT] to [A]\",\n",
    "    \"Then [B] and [A] had a long argument, and afterwards [B] said to [A]\",\n",
    "]\n",
    "\n",
    "TEMPLATES_VARIED_MIDDLE = [\n",
    "    \"\",\n",
    "]\n",
    "\n",
    "# no end of texts, GPT-2 small wasn't trained this way (ask Arthur)\n",
    "# warnings.warn(\"Adding end of text prefixes!\")\n",
    "# for TEMPLATES in [BABA_TEMPLATES, BABA_EARLY_IOS, BABA_LATE_IOS]:\n",
    "#     for i in range(len(TEMPLATES)):\n",
    "#         TEMPLATES[i] = \"<|endoftext|>\" + TEMPLATES[i]\n",
    "\n",
    "ABBA_TEMPLATES = BABA_TEMPLATES[:]\n",
    "ABBA_LATE_IOS = BABA_LATE_IOS[:]\n",
    "ABBA_EARLY_IOS = BABA_EARLY_IOS[:]\n",
    "\n",
    "for TEMPLATES in [ABBA_TEMPLATES, ABBA_LATE_IOS, ABBA_EARLY_IOS]:\n",
    "    for i in range(len(TEMPLATES)):\n",
    "        first_clause = True\n",
    "        for j in range(1, len(TEMPLATES[i]) - 1):\n",
    "            if TEMPLATES[i][j - 1 : j + 2] == \"[B]\" and first_clause:\n",
    "                TEMPLATES[i] = TEMPLATES[i][:j] + \"A\" + TEMPLATES[i][j + 1 :]\n",
    "            elif TEMPLATES[i][j - 1 : j + 2] == \"[A]\" and first_clause:\n",
    "                first_clause = False\n",
    "                TEMPLATES[i] = TEMPLATES[i][:j] + \"B\" + TEMPLATES[i][j + 1 :]\n",
    "\n",
    "VERBS = [\" tried\", \" said\", \" decided\", \" wanted\", \" gave\"]\n",
    "PLACES = [\n",
    "    \"store\",\n",
    "    \"garden\",\n",
    "    \"restaurant\",\n",
    "    \"school\",\n",
    "    \"hospital\",\n",
    "    \"office\",\n",
    "    \"house\",\n",
    "    \"station\",\n",
    "]\n",
    "OBJECTS = [\n",
    "    \"ring\",\n",
    "    \"kiss\",\n",
    "    \"bone\",\n",
    "    \"basketball\",\n",
    "    \"computer\",\n",
    "    \"necklace\",\n",
    "    \"drink\",\n",
    "    \"snack\",\n",
    "]\n",
    "ANIMALS = [\n",
    "    \"dog\",\n",
    "    \"cat\",\n",
    "    \"snake\",\n",
    "    \"elephant\",\n",
    "    \"beetle\",\n",
    "    \"hippo\",\n",
    "    \"giraffe\",\n",
    "    \"tiger\",\n",
    "    \"husky\",\n",
    "    \"lion\",\n",
    "    \"panther\",\n",
    "    \"whale\",\n",
    "    \"dolphin\",\n",
    "    \"beaver\",\n",
    "    \"rabbit\",\n",
    "    \"fox\",\n",
    "    \"lamb\",\n",
    "    \"ferret\",\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
